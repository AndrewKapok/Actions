name: Run Ollama with DeepSeek Model

on:
  workflow_dispatch:  # 手动触发
    inputs:
      model_tag:
        description: 'Model tag to use'
        required: true
        default: 'huihui_ai/deepseek-r1-abliterated:1.5b'
      temperature:
        description: 'Temperature for generation (0.1-2.0)'
        required: false
        default: '0.7'

jobs:
  run-ollama:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests

    - name: Create necessary directories
      run: |
        mkdir -p logs
        mkdir -p results
        echo "Directories created"

    - name: Install Ollama
      run: |
        
        # 安装Ollama
        curl -fsSL https://ollama.com/install.sh | sh
        
        # 等待Ollama服务启动
        sleep 5
        echo "Ollama installed successfully"

    - name: Start Ollama service
      run: |
        # 确保Ollama服务正在运行
        sudo systemctl start ollama || true
        sleep 10
        
        # 检查服务状态
        if systemctl is-active --quiet ollama; then
          echo "Ollama service is running via systemd"
        else
          # 如果systemd服务失败，尝试直接运行
          nohup ollama serve > ollama.log 2>&1 &
          echo "Started Ollama service manually"
          sleep 10
        fi
        
        # 检查端口是否可用
        if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
          echo "Ollama API is accessible"
        else
          echo "Warning: Ollama API may not be ready yet"
        fi

    - name: Pull model
      run: |
        ollama pull ${{ github.event.inputs.model_tag || 'huihui_ai/deepseek-r1-abliterated:1.5b' }}
        echo "Model pulled successfully"

    - name: Run Python script
      env:
        PROMPTS_JSON: ${{ secrets.PROMPTS_JSON }}
        MODEL_TAG: ${{ github.event.inputs.model_tag || 'huihui_ai/deepseek-r1-abliterated:1.5b' }}
        TEMPERATURE: ${{ github.event.inputs.temperature || '0.7' }}
      run: |
        echo "Running Python script..."
        python run_prompts.py

    - name: Upload results as artifact
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: ollama-results
        path: |
          results/
          logs/
          ollama.log
        retention-days: 7

    - name: Clean up
      if: always()
      run: |
        echo "Cleaning up..."
        # 停止Ollama服务
        sudo systemctl stop ollama 2>/dev/null || true
        # 尝试停止手动启动的服务
        pkill -f "ollama serve" 2>/dev/null || true
        sleep 3
